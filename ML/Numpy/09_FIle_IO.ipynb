{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93400e21-9b0c-46b4-989b-9df4433a4e58",
   "metadata": {},
   "source": [
    "# <center> <div style=\"width: 370px;\"> ![numpy title](pictures/numpy_tytle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df08b01a-604b-4e34-afa5-64719affe55b",
   "metadata": {},
   "source": [
    "# <center> File I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2d4823-2a78-4b35-9ded-a071b58e6df7",
   "metadata": {},
   "source": [
    "## File I/O and Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48639d1-b30d-43c8-b1a8-93f31a12e2e5",
   "metadata": {},
   "source": [
    "**Exploring Data with NumPy and File I/O**\n",
    "\n",
    "Now that we've harnessed the power of NumPy for array computation and manipulation, and we've become proficient in constructing record arrays, it's time to embark on some real-world data analysis adventures. In this segment, we'll dive into the world of file input/output (I/O) and learn how to seamlessly integrate external data into NumPy arrays, as well as save our processed results for further analysis.\n",
    "\n",
    "In this exciting journey, you will gain valuable insights into the art of loading and importing diverse datasets. The right approach to data loading depends on the specific file `type` you're dealing with. Whether it's text files, SAS/Stata files, HDF5 files, or other formats, we'll equip you with the essential skills.\n",
    "\n",
    "HDF (Hierarchical Data Format) stands out as one of the go-to choices for efficiently storing and organizing copious amounts of data, making it particularly indispensable when working with multidimensional, homogeneous arrays. To simplify your interaction with HDF5 files, we'll introduce you to Pandas' remarkable HDFStore class, designed to streamline your data manipulation efforts.\n",
    "\n",
    "As you delve deeper into the realm of data science projects, you'll encounter an array of file formats. Fear not, for we shall unravel the mysteries of the most commonly used ones, such as ***NumPy binary files, plain text files*** (`.txt`), and the ubiquitous ***Comma Separated Values*** (`.csv`) files. Armed with this knowledge, you'll be well-prepared to tackle a wide range of data analysis challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04300b00-2198-4c50-908e-0edb84b11cc2",
   "metadata": {},
   "source": [
    "## Text and CSV Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0ad16a-e468-4d10-b641-8a3cbf06d87e",
   "metadata": {},
   "source": [
    "We should talk about reading the file first and then exporting the file. But now, we are going to reverse the process, and create a record array first and then output the array to a CSV file. We read the exported CSV file into the NumPy record arrays and compared it with our original record array. The sample array we're going to create will contain an `id` field with consecutive integers, a `value` field containing random floats, and a `date` field juat number of day in the year. This exercise will use all the knowledge you gained from the previous sections and chapters. Let's start creating the record array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5fddf7-8510-40eb-abf1-67bf9ec2724b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365a7195-f2ef-4dc8-9a05-378a2515c0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "id_ = np.arange(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2761487-a4a4-4984-bbb3-2acc02d02777",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value = np.random.random(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe94470-3819-4431-804d-ed00e104e258",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "day = np.random.randint(0, 366, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6901c38f-4042-4c69-abd1-a603da6d45f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "record_array = np.core.records.fromarrays(\n",
    "    [id_, value, day],\n",
    "    names='id, value, day',\n",
    "    formats='i4, f4, i4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5beb9cb0-430c-4a9f-89c5-795821785461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rec.array([(0, 0.5390407 ,  25), (1, 0.3517334 ,  42),\n",
       "           (2, 0.47612056, 289), (3, 0.15126763,  85),\n",
       "           (4, 0.9585677 , 245), (5, 0.47141927, 307),\n",
       "           (6, 0.7562439 , 303), (7, 0.44614092, 360),\n",
       "           (8, 0.2888388 ,   1), (9, 0.5640747 , 360)],\n",
       "          dtype=[('id', '<i4'), ('value', '<f4'), ('day', '<i4')])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_array[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21a68f-9c6f-4416-b658-dda4c4555669",
   "metadata": {},
   "source": [
    "We first creat three NumPy representing the fields we need: `id`, `value`, and `date`.\n",
    "Then we use the `numpy.core.records.fromarrays()` function to merge the three array into record array and assign the `names` (field name).\n",
    "what we are going to do next-exporting the record array to a CSV file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d51fa1-9c3f-4578-88bc-6e8497354105",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savetxt('./record.csv', record_array, fmt='%.4i, %.4f, %.4i')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4e6b85-5272-4782-b86a-c7fdd507916d",
   "metadata": {},
   "source": [
    "We use the `numpy.savetxt()` function to handle the exporting, and we specify the first argument as the exported file location, the array name, and the format using the `fmt` argument. We have three fields with two different data types and we want to add `,` in between each field in the CSV file. If you prefer any other delimiters, replace the comma in the `fmt` argument. We also get rid of redundant digits in the value field, so we specify only four digits after the decimal points to the file by using `%.4f`. Now you may go to the file location we specified in the first argument to check the CSV file. Open it in a spreadsheet software program and you can see the following:\n",
    "\n",
    "```csv\n",
    "0, 0.7436445 , 334\n",
    "1, 0.1363907 , 281\n",
    "2, 0.28818563, 118 \n",
    "3, 0.3506355 , 184\n",
    "4, 0.03474142, 105 \n",
    "5, 0.23175852, 280\n",
    "6, 0.34881884, 273 \n",
    "7, 0.17016436, 246\n",
    "8, 0.29626068,  17 \n",
    "9, 0.17631991, 161\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ea6e6d-bd02-4004-853c-45b61ceb090f",
   "metadata": {},
   "source": [
    "Next, we are going to read the CSV file to a record array and use the `value` field to generate a mask field, named `mask`, which represents a value larger than or equal to 0.75. Then we will append the new mask field to the record array. Let's read the CSV file first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce379f0c-c2fa-4d5b-a8b5-9ad68d5fa52a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = read_array = np.genfromtxt(\n",
    "    './record.csv',\n",
    "    dtype='i4, f4, i4',\n",
    "    delimiter=',',\n",
    "    skip_header=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "176b5e85-7568-4ab3-a4ae-ebfc66979d70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype([('f0', '<i4'), ('f1', '<f4'), ('f2', '<i4')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30705d6c-4910-4e36-b65d-a7e217b58640",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0.539, 25)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59febfff-dbc6-45a0-9f48-9264c7f16083",
   "metadata": {},
   "source": [
    "We employ the `numpy.genfromtxt()` function to efficiently ingest data from the specified file and transform it into a NumPy record array. The first argument supplied to this function is the file's location, while the optional `dtype` argument allows us to explicitly define the data type. It's highly recommended to specify the `dtype` argument to ensure proper data interpretation, especially when you have prior knowledge of the data's structure.\n",
    "\n",
    "Furthermore, the `delimiter` argument, although optional, allows us to specify the character used to separate values within the file. By default, consecutive whitespaces serve as delimiters, but in our case, we've used `\",\"` as the delimiter since we're working with a CSV file. \n",
    "\n",
    "Another optional argument we've utilized is `skip_header`, which enables us to skip a specified number of lines at the beginning of the file. While our data didn't include field names at the top, NumPy provides this functionality, making it flexible for various data sources.\n",
    "\n",
    "In addition to `skip_header`, the `numpy.genfromtext()` function offers 22 more operation parameters that allow for fine-tuning the resulting array, such as handling missing values and specifying fill values. For comprehensive details on these parameters, please consult the official documentation at https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.genfromtxt.html.\n",
    "\n",
    "Now that the data has been successfully loaded into the record array, you may notice that the second field contains more than four digits after the decimal point, as we previously specified when exporting the CSV. This behavior is due to our choice of `f4` as the data type during the read-in process. NumPy automatically fills in any empty digits, but the valid four digits from the file remain unchanged.\n",
    "\n",
    "One final observation is the absence of field names in our record array. To address this, let's explicitly specify the field names to ensure clarity and ease of data manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef66ccea-1f01-43be-82a0-f7971119fea8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "read_array.dtype.names = ('id', 'value', 'date') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3096cce-ce21-4e26-b1f2-1264336b0f10",
   "metadata": {},
   "source": [
    "## `.npy` or `.npz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2dd25-f478-418d-aba6-aa60ca92c088",
   "metadata": {},
   "source": [
    "When dealing with arrays in your data workflow, it's a common practice to preserve them as NumPy binary files once your work is complete. This approach offers several advantages, primarily because it allows you to retain crucial information about the array, including its shape and data type. This stored knowledge becomes invaluable when you later reload the array, as NumPy seamlessly recalls these attributes, enabling you to pick up your work exactly where you left off.\n",
    "\n",
    "What's even more remarkable about NumPy binary files is their cross-platform compatibility. Regardless of whether you transfer the file to another machine with a different architecture, the stored information about the array remains intact and interpretable. This robust portability underscores the utility of NumPy binary files in data sharing and collaboration.\n",
    "\n",
    "To facilitate the creation and retrieval of NumPy binary files, NumPy provides a suite of methods, including `load()`, `save()`, `savez()`, and `savez_compressed()`. These functions empower you to effortlessly load and save NumPy binary files, ensuring the preservation of your array data and its characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f167a33-b061-4ff8-9ec9-85c5db6871f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example_array = np.arange(12).reshape(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35972645-52ea-4668-84ab-52515628ca97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for why `allow_pickle` is set to false, read the note mentioned in a few lines below.\n",
    "np.save('example.npy', example_array, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc35273a-f235-4b16-ad62-d9e29a92dafa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = np.load('example.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ec042fe-c646-4eeb-a1e6-33e49006a318",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e40b4f65-dbf2-4fa3-ac9d-8c57c19ec083",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "361added-e08f-473a-8fb8-670e6c114cd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(d == example_array).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b525de30-2503-4154-b709-38d977e2bfcb",
   "metadata": {},
   "source": [
    "In the provided code snippet, we perform the following steps to demonstrate the process of saving an array as a binary file and subsequently loading it without altering its shape:\n",
    "\n",
    "1. We initiate the process by creating an array with a designated shape of `(3, 4)`.\n",
    "\n",
    "2. Next, we save this array as a binary file.\n",
    "\n",
    "3. Following the save operation, we proceed to load the saved array from the binary file.\n",
    "\n",
    "4. Crucially, we verify whether the array's original shape remains unchanged after the load operation.\n",
    "\n",
    "> **NOte:** It's worth noting that unless the `dtype` of the array includes Python objects, we should set `allow_pickle=False` when using both `numpy.save()` and `numpy.load()`. This configuration is essential to ensure that the array is saved and loaded efficiently without relying on the pickling mechanism. It's important to keep in mind that pickles are not secure against data that may be erroneous or maliciously constructed.\n",
    "\n",
    "Furthermore, for scenarios where you need to save multiple arrays into a single file, you can effectively employ the `savez()` function. If you seek to optimize storage space by compressing your NumPy binary files, you can employ the `savez_compressed()` function, enhancing the efficiency of file storage and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48581a27-e453-42b0-a956-2a9b1a91e1de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = np.arange(5)\n",
    "y = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f58b296b-29cc-4f0b-ab3e-cf354216f9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez('x_y.npz', x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b2da37d-053e-438f-9d48-02e6f9092108",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "npzfile = np.load('x_y.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b3b07cd-5aa8-47cd-b21c-48d22cbc888f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arr_0', 'arr_1']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2eae74c-f42b-42b3-a709-71abd87cf4a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91e4f71c-5eaf-40bd-9c41-d4f0ced72cc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['arr_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23510af6-8001-433d-92c4-c1691457573c",
   "metadata": {},
   "source": [
    "When you save several arrays in a single file, if you give a keyword argument such as `first_array=x`, your array will be saved with this name. Otherwise, by default, your first array will be given a variable name, such as `arr_0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ecc4ff0-405e-405f-8a1c-43856a777cfd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.savez_compressed('x_y_compressed.npz', first_array=x , second_array=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14e4043b-ad6b-4122-993a-e53468e0621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "npzfile = np.load('x_y_compressed.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bed5eae-c452-4c42-84c0-792614c42312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first_array', 'second_array']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8f1b0d1-d444-4378-93d4-64bf7206e1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['first_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54862535-d2cf-49d4-81e1-e71354c8ca49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npzfile['second_array']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2015b4-b2b1-4b9e-940b-ae93b2e8e073",
   "metadata": {},
   "source": [
    "> **Note:** As a general guideline, it is advisable to prioritize the use of `numpy.save` and `numpy.load` over `numpy.ndarray.tofile` and `numpy.fromfile`. The reason for this preference lies in the fact that the latter methods tend to lose crucial information pertaining to endianness and precision. Consequently, they are best suited for temporary or scratch storage purposes, making them less suitable for applications requiring robust data preservation and compatibility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95f150d-592f-425c-a940-b28d36fd8fe9",
   "metadata": {},
   "source": [
    "## `json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738049da-a9d6-4fb3-ba55-dd248b38a3d1",
   "metadata": {},
   "source": [
    "> **Warning:** NumPy arrays are not directly JSON serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25facf-3328-46af-b2b0-c83e603d8aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
